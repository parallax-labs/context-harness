<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Context Harness ‚Äî Live Demo (Browser)</title>
<meta name="description" content="Try Context Harness in your browser. No server, no API keys. Keyword and semantic search over a real knowledge base, running entirely client-side.">
<link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚ö°</text></svg>">
<style>
  :root {
    --bg: #0a0e17;
    --surface: #111827;
    --surface-2: #1a2332;
    --surface-3: #0f1a2a;
    --border: #1e2d3d;
    --text: #e2e8f0;
    --text-dim: #8892a4;
    --accent: #3b82f6;
    --accent-glow: rgba(59, 130, 246, 0.15);
    --green: #22c55e;
    --yellow: #eab308;
    --red: #ef4444;
    --orange: #f97316;
    --purple: #a855f7;
    --teal: #14b8a6;
    --radius: 12px;
    --mono: 'SF Mono', 'Fira Code', 'JetBrains Mono', monospace;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
    background: var(--bg);
    color: var(--text);
    min-height: 100vh;
    line-height: 1.6;
  }

  /* ‚îÄ‚îÄ Header ‚îÄ‚îÄ */
  header {
    border-bottom: 1px solid var(--border);
    padding: 14px 24px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    background: var(--surface);
    position: sticky;
    top: 0;
    z-index: 100;
  }

  .logo { display: flex; align-items: center; gap: 12px; font-weight: 700; font-size: 18px; }
  .logo-icon { width: 32px; height: 32px; background: linear-gradient(135deg, var(--accent), var(--purple)); border-radius: 8px; display: flex; align-items: center; justify-content: center; font-size: 16px; }

  .header-right { display: flex; align-items: center; gap: 16px; }

  .nav-tabs { display: flex; gap: 4px; background: var(--surface-2); border-radius: 8px; padding: 3px; }
  .nav-tab { padding: 6px 16px; border-radius: 6px; border: none; background: transparent; color: var(--text-dim); font-size: 13px; cursor: pointer; transition: all 0.2s; font-family: inherit; font-weight: 500; }
  .nav-tab:hover { color: var(--text); }
  .nav-tab.active { background: var(--accent); color: white; }

  .back-link { color: var(--text-dim); font-size: 13px; text-decoration: none; }
  .back-link:hover { color: var(--accent); }

  .status-pill { display: flex; align-items: center; gap: 8px; padding: 4px 12px; border-radius: 20px; background: var(--surface-2); border: 1px solid var(--border); }
  .status-dot { width: 7px; height: 7px; border-radius: 50%; background: var(--green); }
  .status-label { font-size: 12px; color: var(--text-dim); font-family: var(--mono); }

  /* ‚îÄ‚îÄ Pages ‚îÄ‚îÄ */
  .page { display: none; }
  .page.active { display: block; }
  .container { max-width: 1100px; margin: 0 auto; padding: 32px 24px; }

  /* ‚îÄ‚îÄ Info Tips ‚îÄ‚îÄ */
  .info-tip {
    display: inline-flex; align-items: center; justify-content: center;
    width: 18px; height: 18px; border-radius: 50%;
    background: var(--surface-2); border: 1px solid var(--border);
    color: var(--text-dim); font-size: 11px; cursor: help;
    position: relative; vertical-align: middle; margin-left: 4px; flex-shrink: 0;
  }
  .info-tip:hover { border-color: var(--accent); color: var(--accent); }
  .info-tip .tip-text {
    display: none; position: absolute; bottom: calc(100% + 8px); left: 50%; transform: translateX(-50%);
    background: var(--surface); border: 1px solid var(--border); border-radius: 8px;
    padding: 12px 16px; font-size: 13px; color: var(--text); width: 320px; line-height: 1.5;
    box-shadow: 0 8px 24px rgba(0,0,0,0.4); z-index: 200;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
    font-weight: 400; text-align: left; cursor: default;
  }
  .info-tip:hover .tip-text { display: block; }
  .tip-text::after { content: ''; position: absolute; top: 100%; left: 50%; transform: translateX(-50%); border: 6px solid transparent; border-top-color: var(--border); }

  /* ‚îÄ‚îÄ Banners ‚îÄ‚îÄ */
  .learn-banner {
    background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius);
    padding: 16px 20px; margin-bottom: 24px; display: flex; align-items: flex-start; gap: 12px;
    font-size: 14px; color: var(--text-dim); line-height: 1.6;
  }
  .learn-banner .banner-icon { font-size: 20px; flex-shrink: 0; margin-top: 1px; }
  .learn-banner strong { color: var(--text); }
  .learn-banner code { background: var(--surface-2); padding: 2px 6px; border-radius: 4px; font-family: var(--mono); font-size: 12px; color: var(--accent); }

  /* ‚îÄ‚îÄ Search Section ‚îÄ‚îÄ */
  .search-section { margin-bottom: 24px; }
  .section-label { display: flex; align-items: center; gap: 6px; font-size: 11px; text-transform: uppercase; letter-spacing: 1.5px; color: var(--text-dim); margin-bottom: 10px; font-weight: 600; }

  .search-box { display: flex; gap: 0; background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); overflow: hidden; transition: border-color 0.2s; }
  .search-box:focus-within { border-color: var(--accent); box-shadow: 0 0 0 3px var(--accent-glow); }
  .search-input { flex: 1; padding: 14px 20px; background: transparent; border: none; color: var(--text); font-size: 16px; outline: none; font-family: inherit; }
  .search-input::placeholder { color: var(--text-dim); }
  .search-btn { padding: 14px 24px; background: var(--accent); color: white; border: none; font-size: 14px; font-weight: 600; cursor: pointer; transition: background 0.2s; white-space: nowrap; }
  .search-btn:hover { background: #2563eb; }

  /* ‚îÄ‚îÄ Mode Selector ‚îÄ‚îÄ */
  .mode-section { display: flex; align-items: center; gap: 12px; margin-top: 14px; flex-wrap: wrap; }
  .mode-btn { padding: 8px 18px; border-radius: 20px; border: 1px solid var(--border); background: var(--surface); color: var(--text-dim); font-size: 13px; cursor: pointer; transition: all 0.2s; font-family: var(--mono); }
  .mode-btn:hover { border-color: var(--accent); color: var(--text); }
  .mode-btn.active { background: var(--accent-glow); border-color: var(--accent); color: var(--accent); }
  .mode-btn.loading { opacity: 0.6; cursor: wait; }

  /* ‚îÄ‚îÄ Mode Explainer ‚îÄ‚îÄ */
  .mode-explainer {
    margin-top: 14px; padding: 14px 18px; background: var(--surface);
    border: 1px solid var(--border); border-left: 3px solid var(--accent);
    border-radius: 0 var(--radius) var(--radius) 0; font-size: 13px; color: var(--text-dim); line-height: 1.6;
  }
  .mode-explainer strong { color: var(--text); }
  .mode-explainer code { background: var(--surface-2); padding: 1px 5px; border-radius: 3px; font-family: var(--mono); font-size: 12px; color: var(--accent); }

  /* ‚îÄ‚îÄ Model Progress ‚îÄ‚îÄ */
  .model-progress {
    display: none; margin-top: 12px; padding: 14px 18px; background: var(--surface);
    border: 1px solid rgba(168, 85, 247, 0.3); border-radius: var(--radius); font-size: 13px;
  }
  .model-progress.visible { display: block; }
  .model-progress .prog-header { display: flex; justify-content: space-between; margin-bottom: 8px; color: var(--text-dim); }
  .model-progress .prog-label { font-weight: 600; color: var(--purple); }
  .model-progress .prog-bar { height: 6px; background: var(--surface-2); border-radius: 3px; overflow: hidden; }
  .model-progress .prog-fill { height: 100%; background: linear-gradient(90deg, var(--accent), var(--purple)); border-radius: 3px; width: 0%; transition: width 0.3s; }
  .model-progress .prog-detail { margin-top: 6px; font-size: 11px; color: var(--text-dim); font-family: var(--mono); }

  /* ‚îÄ‚îÄ Stats ‚îÄ‚îÄ */
  .stats-bar { display: none; gap: 20px; margin-top: 14px; padding: 10px 16px; background: var(--surface); border-radius: var(--radius); border: 1px solid var(--border); font-size: 12px; flex-wrap: wrap; }
  .stats-bar.visible { display: flex; }
  .stat { display: flex; align-items: center; gap: 5px; color: var(--text-dim); font-family: var(--mono); }
  .stat-value { color: var(--accent); font-weight: 600; }

  /* ‚îÄ‚îÄ Suggestions ‚îÄ‚îÄ */
  .suggestions { display: flex; flex-wrap: wrap; justify-content: center; gap: 8px; margin-top: 20px; }
  .suggestion { padding: 8px 16px; border-radius: 20px; border: 1px solid var(--border); background: var(--surface); color: var(--text-dim); font-size: 13px; cursor: pointer; transition: all 0.2s; }
  .suggestion:hover { border-color: var(--accent); color: var(--accent); background: var(--accent-glow); }

  /* ‚îÄ‚îÄ Results ‚îÄ‚îÄ */
  .results-area { margin-top: 24px; }
  .empty-state { text-align: center; padding: 48px 24px; color: var(--text-dim); }
  .empty-state .icon { font-size: 42px; margin-bottom: 12px; opacity: 0.5; }
  .empty-state h3 { font-size: 17px; margin-bottom: 6px; color: var(--text); }
  .empty-state p { font-size: 14px; }

  .result-card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); padding: 18px 20px; margin-bottom: 10px; cursor: pointer; transition: all 0.2s; }
  .result-card:hover { border-color: var(--accent); transform: translateY(-1px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3); }

  .result-header { display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 6px; }
  .result-title { font-weight: 600; font-size: 15px; color: var(--text); }
  .result-score { font-family: var(--mono); font-size: 12px; padding: 2px 10px; border-radius: 12px; font-weight: 600; flex-shrink: 0; margin-left: 12px; }
  .score-high { background: rgba(34, 197, 94, 0.15); color: var(--green); }
  .score-mid { background: rgba(234, 179, 8, 0.15); color: var(--yellow); }
  .score-low { background: rgba(239, 68, 68, 0.15); color: var(--red); }

  .result-meta { display: flex; gap: 14px; font-size: 12px; color: var(--text-dim); margin-bottom: 8px; flex-wrap: wrap; }
  .result-snippet { font-size: 13px; color: var(--text-dim); line-height: 1.6; border-left: 2px solid var(--border); padding-left: 12px; }
  .result-snippet mark { background: var(--accent-glow); color: var(--accent); border-radius: 2px; padding: 0 2px; }

  .result-learn { margin-top: 10px; padding: 10px 14px; background: var(--surface-2); border-radius: 8px; font-size: 12px; color: var(--text-dim); line-height: 1.5; border-left: 2px solid var(--teal); }
  .result-learn strong { color: var(--teal); }

  .doc-detail { margin-top: 12px; padding-top: 14px; border-top: 1px solid var(--border); display: none; }
  .doc-detail.visible { display: block; }
  .doc-body { background: var(--surface-2); border: 1px solid var(--border); border-radius: 8px; padding: 18px; font-size: 13px; line-height: 1.7; color: var(--text); max-height: 380px; overflow-y: auto; white-space: pre-wrap; font-family: var(--mono); }
  .chunk-tag { display: inline-block; padding: 3px 10px; background: var(--surface-2); border: 1px solid var(--border); border-radius: 6px; font-size: 11px; font-family: var(--mono); color: var(--text-dim); margin: 2px 4px 2px 0; }
  .doc-learn { margin-top: 12px; padding: 12px 16px; background: rgba(20, 184, 166, 0.06); border: 1px solid rgba(20, 184, 166, 0.15); border-radius: 8px; font-size: 12px; color: var(--text-dim); line-height: 1.5; }
  .doc-learn strong { color: var(--teal); }

  .loading { text-align: center; padding: 40px; color: var(--text-dim); }
  .spinner { width: 28px; height: 28px; border: 3px solid var(--border); border-top-color: var(--accent); border-radius: 50%; animation: spin 0.8s linear infinite; margin: 0 auto 12px; }
  @keyframes spin { to { transform: rotate(360deg); } }
  .error-msg { text-align: center; padding: 20px; color: var(--red); background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.2); border-radius: var(--radius); font-family: var(--mono); font-size: 13px; }

  /* ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê */
  /* ‚îÄ‚îÄ About Page ‚îÄ‚îÄ */
  /* ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê */
  .about-hero { text-align: center; padding: 40px 0 32px; border-bottom: 1px solid var(--border); margin-bottom: 40px; }
  .about-hero h1 { font-size: 32px; font-weight: 700; margin-bottom: 10px; background: linear-gradient(135deg, var(--text), var(--accent)); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
  .about-hero p { font-size: 16px; color: var(--text-dim); max-width: 640px; margin: 0 auto; }

  .about-section { margin-bottom: 48px; }
  .about-section h2 { font-size: 20px; font-weight: 700; margin-bottom: 16px; color: var(--text); display: flex; align-items: center; gap: 10px; }
  .about-section h2 .num { display: inline-flex; align-items: center; justify-content: center; width: 28px; height: 28px; background: var(--accent); color: white; border-radius: 8px; font-size: 14px; flex-shrink: 0; }
  .about-section p, .about-section li { color: var(--text-dim); font-size: 15px; line-height: 1.7; margin-bottom: 10px; }
  .about-section ul { list-style: none; padding: 0; }
  .about-section li::before { content: '‚Üí '; color: var(--accent); font-weight: 700; }
  .about-section code { background: var(--surface-2); padding: 2px 7px; border-radius: 4px; font-family: var(--mono); font-size: 13px; color: var(--accent); }

  .pipeline { display: flex; align-items: stretch; gap: 0; margin: 24px 0; overflow-x: auto; padding-bottom: 8px; }
  .pipe-step { flex: 1; min-width: 140px; background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); padding: 16px; text-align: center; position: relative; }
  .pipe-step::after { content: '‚Üí'; position: absolute; right: -14px; top: 50%; transform: translateY(-50%); color: var(--accent); font-size: 18px; font-weight: 700; z-index: 1; }
  .pipe-step:last-child::after { content: ''; }
  .pipe-step .step-icon { font-size: 24px; margin-bottom: 8px; }
  .pipe-step .step-title { font-size: 13px; font-weight: 700; color: var(--text); margin-bottom: 4px; }
  .pipe-step .step-desc { font-size: 11px; color: var(--text-dim); line-height: 1.4; }
  .pipe-step.browser-step { border-color: var(--green); box-shadow: 0 0 12px rgba(34, 197, 94, 0.1); }

  .concept-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin-top: 16px; }
  .concept-card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); padding: 20px; }
  .concept-card h3 { font-size: 15px; font-weight: 700; margin-bottom: 8px; color: var(--text); display: flex; align-items: center; gap: 8px; }
  .concept-card p { font-size: 13px; color: var(--text-dim); line-height: 1.6; margin-bottom: 0; }
  .concept-card code { background: var(--surface-2); padding: 1px 5px; border-radius: 3px; font-family: var(--mono); font-size: 12px; color: var(--accent); }

  .try-it { background: var(--accent-glow); border: 1px solid rgba(59, 130, 246, 0.25); border-radius: var(--radius); padding: 16px 20px; margin-top: 16px; display: flex; align-items: center; gap: 12px; cursor: pointer; transition: all 0.2s; }
  .try-it:hover { border-color: var(--accent); transform: translateY(-1px); }
  .try-it .try-icon { font-size: 20px; }
  .try-it .try-text { font-size: 14px; color: var(--accent); font-weight: 600; }
  .try-it .try-sub { font-size: 12px; color: var(--text-dim); margin-top: 2px; }

  .browser-badge { display: inline-block; padding: 3px 10px; border-radius: 100px; font-size: 11px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.5px; }
  .badge-browser { background: rgba(34, 197, 94, 0.15); color: var(--green); border: 1px solid rgba(34, 197, 94, 0.3); }
  .badge-server { background: rgba(168, 85, 247, 0.15); color: var(--purple); border: 1px solid rgba(168, 85, 247, 0.3); }

  /* ‚îÄ‚îÄ Use Cases ‚îÄ‚îÄ */
  .uc-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; margin-top: 16px; }
  .uc-card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); padding: 20px; }
  .uc-card.featured { border-color: var(--accent); box-shadow: 0 0 16px var(--accent-glow); }
  .uc-card h3 { font-size: 15px; font-weight: 700; margin-bottom: 8px; color: var(--text); }
  .uc-card p { font-size: 13px; color: var(--text-dim); line-height: 1.6; margin-bottom: 0; }
  .uc-card em { color: var(--accent); }

  @media (max-width: 640px) {
    .container { padding: 16px; }
    .about-hero h1 { font-size: 24px; }
    .pipeline { flex-direction: column; gap: 8px; }
    .pipe-step::after { content: '‚Üì'; right: auto; left: 50%; top: auto; bottom: -14px; transform: translateX(-50%); }
    .result-header { flex-direction: column; gap: 6px; }
    .result-score { margin-left: 0; }
    .header-right { gap: 8px; }
  }
</style>
</head>
<body>

<header>
  <a class="logo" href="../" style="text-decoration:none;color:var(--text)">
    <div class="logo-icon">‚ö°</div>
    <span>Context Harness</span>
  </a>
  <div class="header-right">
    <div class="nav-tabs">
      <button class="nav-tab active" onclick="showPage('search')">Search</button>
      <button class="nav-tab" onclick="showPage('about')">About the Demo</button>
    </div>
    <div class="status-pill">
      <div class="status-dot"></div>
      <span class="status-label" id="statusText">loading data‚Ä¶</span>
    </div>
  </div>
</header>

<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<!-- SEARCH PAGE -->
<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="page active" id="page-search">
<div class="container">

  <div class="learn-banner">
    <span class="banner-icon">üåê</span>
    <div>
      <strong>This runs entirely in your browser.</strong> No server, no API keys, no backend. The knowledge base (11 documents, 31 chunks) was pre-built with Context Harness and shipped as a static JSON file. Keyword search uses BM25 implemented in JavaScript. Semantic search uses <code>Transformers.js</code> to run an AI model directly in your browser. Hover the <span class="info-tip" style="display:inline-flex;position:static;vertical-align:middle;margin:0 2px;">?</span> icons for explanations.
    </div>
  </div>

  <div class="search-section">
    <div class="section-label">
      Query
      <span class="info-tip">?<span class="tip-text">Your search runs <strong>entirely in your browser</strong>. For keyword mode, we tokenize your query, compute BM25 scores against each chunk, and rank results ‚Äî all in JavaScript. For semantic mode, your query is converted to a vector embedding using an AI model running locally via WebAssembly.</span></span>
    </div>
    <div class="search-box">
      <input type="text" class="search-input" id="searchInput"
             placeholder="Try: incident response, Kafka consumer lag, what happens when things break‚Ä¶"
             autocomplete="off">
      <button class="search-btn" onclick="doSearch()">Search</button>
    </div>

    <div class="mode-section">
      <div class="section-label" style="margin-bottom:0">
        Mode
        <span class="info-tip">?<span class="tip-text"><strong>keyword</strong> ‚Äî BM25 ranking in pure JavaScript. Matches exact words. Instant.<br><br><strong>semantic</strong> ‚Äî Loads a small AI model (~30MB, cached after first use) to embed your query, then finds conceptually similar chunks via cosine similarity.<br><br><strong>hybrid</strong> ‚Äî Weighted combination of both: <code>score = (1-Œ±)¬∑keyword + Œ±¬∑semantic</code>.</span></span>
      </div>
      <button class="mode-btn active" data-mode="keyword" onclick="setMode(this)">keyword</button>
      <button class="mode-btn" data-mode="semantic" onclick="setMode(this)">semantic</button>
      <button class="mode-btn" data-mode="hybrid" onclick="setMode(this)">hybrid</button>
    </div>

    <div class="mode-explainer" id="modeExplainer">
      <strong>Keyword mode</strong> ‚Äî Uses BM25 ranking implemented in pure JavaScript. Your query is tokenized, and each chunk is scored by term frequency normalized by document length. The formula: <code>score = Œ£ IDF(qi) ¬∑ (tf ¬∑ (k‚ÇÅ+1)) / (tf + k‚ÇÅ ¬∑ (1-b+b¬∑|d|/avgdl))</code>. This runs instantly with no model loading.
    </div>

    <div class="model-progress" id="modelProgress">
      <div class="prog-header">
        <span class="prog-label">üß† Loading AI model for semantic search‚Ä¶</span>
        <span class="prog-pct" id="progPct">0%</span>
      </div>
      <div class="prog-bar"><div class="prog-fill" id="progFill"></div></div>
      <div class="prog-detail" id="progDetail">Downloading all-MiniLM-L6-v2 (~30 MB, cached after first use)</div>
    </div>

    <div class="stats-bar" id="statsBar">
      <div class="stat">results: <span class="stat-value" id="statCount">0</span>
        <span class="info-tip">?<span class="tip-text">The number of <strong>unique documents</strong> returned. Internally, each chunk is scored individually, then chunks are grouped by parent document using MAX aggregation ‚Äî the best chunk's score becomes the document's score.</span></span>
      </div>
      <div class="stat">mode: <span class="stat-value" id="statMode">keyword</span></div>
      <div class="stat">time: <span class="stat-value" id="statTime">0ms</span>
        <span class="info-tip">?<span class="tip-text">Total time for the search computation in your browser. Keyword search is typically &lt;5ms. Semantic search includes query embedding time (~50-200ms after model is loaded). No network latency ‚Äî everything is local.</span></span>
      </div>
      <div class="stat">engine: <span class="stat-value">browser</span> <span class="browser-badge badge-browser">client-side</span></div>
    </div>
  </div>

  <div id="suggestionsArea">
    <div class="empty-state">
      <div class="icon">üîç</div>
      <h3>Search the Acme Engineering Handbook</h3>
      <p>Click a suggestion or type your own query:</p>
      <div class="suggestions">
        <button class="suggestion" onclick="trySuggestion(this)">incident response</button>
        <button class="suggestion" onclick="trySuggestion(this)">Kafka consumer lag</button>
        <button class="suggestion" onclick="trySuggestion(this)">Rust error handling</button>
        <button class="suggestion" onclick="trySuggestion(this)">deployment rollback</button>
        <button class="suggestion" onclick="trySuggestion(this)">on-call rotation</button>
        <button class="suggestion" onclick="trySuggestion(this)">API authentication</button>
        <button class="suggestion" onclick="trySuggestion(this)">what happens when things break</button>
        <button class="suggestion" onclick="trySuggestion(this)">security breach</button>
      </div>
    </div>
  </div>

  <div class="results-area" id="resultsArea"></div>
</div>
</div>

<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<!-- ABOUT PAGE -->
<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="page" id="page-about">
<div class="container">

  <div class="about-hero">
    <h1>About This Demo</h1>
    <p>A fully client-side implementation of Context Harness ‚Äî the same search engine, running entirely in your browser with no server, no API keys, and no backend.</p>
  </div>

  <!-- Section 1: What makes this special -->
  <div class="about-section">
    <h2><span class="num">1</span> What's Special About This Demo?</h2>
    <p>This demo runs <strong>entirely in your browser</strong>. There's no server receiving your queries. No API keys. No backend at all. Here's what's happening under the hood:</p>
    <ul>
      <li>The knowledge base (11 documents, 31 chunks) was <strong>pre-built with Context Harness</strong> and exported as a 107 KB JSON file</li>
      <li><strong>BM25 keyword search</strong> is implemented in ~60 lines of JavaScript ‚Äî the same algorithm SQLite's FTS5 uses, running directly in your browser</li>
      <li><strong>Semantic search</strong> uses <code>Transformers.js</code> to run the <code>all-MiniLM-L6-v2</code> AI model via WebAssembly ‚Äî your query is embedded locally, no API calls</li>
      <li><strong>Hybrid search</strong> combines both signals using min-max normalization and a configurable alpha weight ‚Äî identical to the server implementation</li>
      <li>The AI model (~30 MB) is <strong>downloaded once and cached</strong> by your browser ‚Äî subsequent visits load instantly</li>
    </ul>
    <p>This is the <strong>"Offline-First RAG"</strong> use case in action. Pre-build your knowledge base at build time, ship it as static assets, and your web app gets intelligent search with zero infrastructure.</p>
  </div>

  <!-- Section 2: How it runs in the browser -->
  <div class="about-section">
    <h2><span class="num">2</span> How It Runs in the Browser</h2>
    <p>The pipeline splits into two phases ‚Äî <strong>build time</strong> (runs once) and <strong>runtime</strong> (runs in your browser):</p>

    <div class="pipeline">
      <div class="pipe-step">
        <div class="step-icon">ü¶Ä</div>
        <div class="step-title">Build (Rust)</div>
        <div class="step-desc">ctx sync ‚Üí chunks markdown files, stores in SQLite</div>
      </div>
      <div class="pipe-step">
        <div class="step-icon">üì¶</div>
        <div class="step-title">Export</div>
        <div class="step-desc">Documents + chunks exported to JSON</div>
      </div>
      <div class="pipe-step">
        <div class="step-icon">üöÄ</div>
        <div class="step-title">Deploy</div>
        <div class="step-desc">Static JSON file hosted on GitHub Pages / CDN</div>
      </div>
      <div class="pipe-step browser-step">
        <div class="step-icon">üåê</div>
        <div class="step-title">Browser</div>
        <div class="step-desc">BM25 in JS + Transformers.js for embeddings</div>
      </div>
    </div>

    <p>At build time, Context Harness processes your markdown files through its chunking pipeline ‚Äî splitting at paragraph boundaries, ~500 tokens per chunk. The output is exported to a small JSON file.</p>
    <p>At runtime, your browser loads this JSON and builds an inverted index for BM25. When you switch to semantic or hybrid mode, <code>Transformers.js</code> downloads and caches a small AI model, embeds all 31 chunks (~2 seconds), and stores the vectors. After that, everything is instant.</p>
  </div>

  <!-- Section 3: Search Algorithms -->
  <div class="about-section">
    <h2><span class="num">3</span> How Search Works</h2>

    <div class="concept-grid">
      <div class="concept-card">
        <h3>üî§ BM25 Keyword Search</h3>
        <p>Okapi BM25 is the standard ranking function used by search engines. It scores documents based on <strong>term frequency</strong> (how often your query words appear) normalized by <strong>document length</strong> (so short, focused chunks aren't penalized). The formula uses two parameters: <code>k‚ÇÅ=1.2</code> (term frequency saturation) and <code>b=0.75</code> (length normalization). IDF (Inverse Document Frequency) down-weights common terms and boosts rare ones.</p>
      </div>
      <div class="concept-card">
        <h3>üß† Semantic Search</h3>
        <p>Each chunk and your query are converted to a <strong>384-dimensional vector</strong> by the <code>all-MiniLM-L6-v2</code> model running in your browser via WebAssembly. Vectors that point in similar directions represent similar meanings. <strong>Cosine similarity</strong> measures the angle between vectors ‚Äî identical meaning = 1.0, unrelated = 0.0. This finds results even without matching words: "database crash" matches "PostgreSQL outage".</p>
      </div>
      <div class="concept-card">
        <h3>‚öñÔ∏è Hybrid Search</h3>
        <p>Combines keyword and semantic signals. Both score sets are <strong>min-max normalized</strong> to [0, 1] so they're on the same scale, then merged: <code>score = (1-Œ±)¬∑keyword + Œ±¬∑semantic</code>. The default Œ±=0.6 gives 60% weight to semantic similarity. This catches both exact-term matches and conceptual matches.</p>
      </div>
      <div class="concept-card">
        <h3>üìä Document Grouping</h3>
        <p>Search happens at the <strong>chunk level</strong> ‚Äî each ~500-token segment is scored individually. Multiple chunks from the same document are then grouped using <strong>MAX aggregation</strong>: the document's score is its best chunk's score. This means a document with one highly relevant section ranks above a document with many mediocre matches.</p>
      </div>
    </div>

    <div class="try-it" onclick="showPage('search'); document.getElementById('searchInput').value='what happens when things break'; doSearch();">
      <span class="try-icon">üöÄ</span>
      <div>
        <div class="try-text">Try it: keyword vs semantic</div>
        <div class="try-sub">Search "what happens when things break" ‚Äî keyword finds nothing, semantic finds incident response docs</div>
      </div>
    </div>
  </div>

  <!-- Section 4: Use Cases -->
  <div class="about-section">
    <h2><span class="num">4</span> Use Cases</h2>
    <p>Context Harness is designed for workflows where AI tools need access to structured knowledge. Here are the primary use cases:</p>

    <div class="uc-grid">
      <div class="uc-card featured">
        <h3>üß© Offline-First RAG for Web Apps</h3>
        <p>Pre-build your knowledge base at build time. Ship documents + chunks + embeddings as static assets. Your web app gets retrieval-augmented generation <strong>with zero backend infrastructure</strong>. This demo is a working example ‚Äî hosted on GitHub Pages, running in your browser right now.</p>
      </div>
      <div class="uc-card featured">
        <h3>ü§ñ AI Agent Context in Your IDE</h3>
        <p>Point Context Harness at your repo's docs, ADRs, runbooks, and architecture decisions. Start the MCP server with <code>ctx serve mcp</code>. Now Cursor, Claude, and any MCP-compatible agent can search your project knowledge via structured tool calls ‚Äî no copy-pasting, no wasted context windows.</p>
      </div>
      <div class="uc-card featured">
        <h3>üìù Personal Knowledge Agent</h3>
        <p>Index your Obsidian vault, meeting notes, or research docs. Vectorize everything with embeddings. Connect it to your AI tools and ask questions across your entire body of knowledge ‚Äî <em>"What did we decide about the auth migration?"</em> ‚Äî with citations back to the source.</p>
      </div>
      <div class="uc-card">
        <h3>üìö Documentation Site Search</h3>
        <p>Replace Algolia or DocSearch with self-hosted semantic search. Build the index at deploy time, serve from a CDN. No third-party dependencies, no API keys, no monthly bills, no usage limits.</p>
      </div>
      <div class="uc-card">
        <h3>üèóÔ∏è Engineering Onboarding</h3>
        <p>Index incident reports, post-mortems, architecture decisions, and runbooks. New engineers query naturally: <em>"How do we handle database failovers?"</em> instead of searching Confluence for 45 minutes.</p>
      </div>
      <div class="uc-card">
        <h3>üîó Multi-Source Knowledge Hub</h3>
        <p>Connect filesystem, GitHub issues, Jira tickets, and Slack threads into a single searchable index. Break down knowledge silos across your organization. Query everything from one place.</p>
      </div>
    </div>
  </div>

  <!-- Section 5: What's in the knowledge base -->
  <div class="about-section">
    <h2><span class="num">5</span> What's in the Knowledge Base</h2>
    <p>This demo indexes a fictional <strong>"Acme Engineering Handbook"</strong> ‚Äî 11 documents covering real-world engineering knowledge:</p>

    <div class="concept-grid">
      <div class="concept-card"><h3>üìê Architecture Decisions</h3><p>ADRs covering microservices, Kafka, PostgreSQL selection, and Rust for performance-critical services.</p></div>
      <div class="concept-card"><h3>üö® Incident Response</h3><p>Severity levels, on-call rotation, incident templates, post-mortem process, and common runbooks.</p></div>
      <div class="concept-card"><h3>üöÄ Deployment Pipeline</h3><p>CI/CD stages, canary deployments, rollback procedures, environment promotion, and deployment schedules.</p></div>
      <div class="concept-card"><h3>üì° Observability Stack</h3><p>Metrics (Datadog), structured logging, distributed tracing, SLOs, error budgets, and alerting.</p></div>
      <div class="concept-card"><h3>üîí Security Practices</h3><p>mTLS, Vault secrets management, PII handling, GDPR compliance, and vulnerability management.</p></div>
      <div class="concept-card"><h3>ü¶Ä Rust Best Practices</h3><p>Error handling patterns, async with Tokio, testing strategies, performance tips, and approved crates.</p></div>
    </div>
  </div>

  <!-- Section 6: Server vs Browser comparison -->
  <div class="about-section">
    <h2><span class="num">6</span> Browser vs Server Mode</h2>
    <p>Context Harness supports two deployment modes. This demo shows the browser mode, but the same search engine runs as a server too:</p>

    <div class="concept-grid">
      <div class="concept-card" style="border-color: var(--green);">
        <h3>üåê Browser Mode <span class="browser-badge badge-browser">this demo</span></h3>
        <p>Pre-built data shipped as static JSON. BM25 in JavaScript, embeddings via Transformers.js WASM. No server, no API keys, works offline. Best for: documentation sites, static apps, offline tools, public demos.</p>
      </div>
      <div class="concept-card" style="border-color: var(--purple);">
        <h3>üñ•Ô∏è Server Mode <span class="browser-badge badge-server">MCP server</span></h3>
        <p>Full Rust binary with SQLite, FTS5, sqlite-vec, and OpenAI embeddings. MCP-compatible HTTP server for AI tool integration. Best for: IDE agents (Cursor), local development, multi-connector setups, large corpora.</p>
      </div>
    </div>
  </div>

  <div class="about-section">
    <div class="try-it" onclick="showPage('search');">
      <span class="try-icon">‚¨ÖÔ∏è</span>
      <div>
        <div class="try-text">Back to Search</div>
        <div class="try-sub">Try keyword, semantic, and hybrid search on the Acme Engineering Handbook</div>
      </div>
    </div>
  </div>

</div>
</div>

<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<!-- SCRIPT -->
<!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<script type="module">

// ‚îÄ‚îÄ State ‚îÄ‚îÄ
let DATA = null;           // { documents, chunks }
let currentMode = 'keyword';
let bm25Index = null;      // { idf, avgdl, chunkTermFreqs, chunkLengths }
let pipeline = null;       // Transformers.js pipeline
let chunkEmbeddings = null; // Float32Array[]
let modelLoading = false;
let modelReady = false;

const HYBRID_ALPHA = 0.6;
const BM25_K1 = 1.2;
const BM25_B = 0.75;

const MODE_EXPLANATIONS = {
  keyword: '<strong>Keyword mode</strong> ‚Äî Uses BM25 ranking implemented in pure JavaScript. Your query is tokenized, and each chunk is scored by term frequency normalized by document length. The formula: <code>score = Œ£ IDF(qi) ¬∑ (tf ¬∑ (k‚ÇÅ+1)) / (tf + k‚ÇÅ ¬∑ (1-b+b¬∑|d|/avgdl))</code>. This runs instantly with no model loading.',
  semantic: '<strong>Semantic mode</strong> ‚Äî Your query is converted to a 384-dimensional vector by the <code>all-MiniLM-L6-v2</code> model running in your browser via WebAssembly. Each chunk was also embedded into a vector. <strong>Cosine similarity</strong> measures how closely the meanings align. This finds conceptually related content even without matching words.',
  hybrid: '<strong>Hybrid mode</strong> ‚Äî Combines keyword and semantic signals. Both score sets are min-max normalized to [0, 1], then merged: <code>score = (1-Œ±)¬∑keyword + Œ±¬∑semantic</code>. With Œ±=0.6, semantic gets 60% weight. This catches both exact-term matches and conceptual matches ‚Äî the best of both worlds.',
};

// ‚îÄ‚îÄ Page Navigation ‚îÄ‚îÄ
window.showPage = function(page) {
  document.querySelectorAll('.page').forEach(p => p.classList.remove('active'));
  document.querySelectorAll('.nav-tab').forEach(t => t.classList.remove('active'));
  document.getElementById(`page-${page}`).classList.add('active');
  document.querySelector(`[onclick="showPage('${page}')"]`).classList.add('active');
  window.scrollTo(0, 0);
};

// ‚îÄ‚îÄ Tokenizer ‚îÄ‚îÄ
function tokenize(text) {
  return text.toLowerCase().replace(/[^a-z0-9\s]/g, ' ').split(/\s+/).filter(t => t.length > 1);
}

// ‚îÄ‚îÄ Build BM25 Index ‚îÄ‚îÄ
function buildBM25Index(chunks) {
  const N = chunks.length;
  const df = {};       // term -> doc frequency
  const tfs = [];      // per-chunk term frequencies
  const lengths = [];  // per-chunk token counts

  for (const chunk of chunks) {
    const tokens = tokenize(chunk.text);
    lengths.push(tokens.length);
    const tf = {};
    const seen = new Set();
    for (const t of tokens) {
      tf[t] = (tf[t] || 0) + 1;
      if (!seen.has(t)) { df[t] = (df[t] || 0) + 1; seen.add(t); }
    }
    tfs.push(tf);
  }

  const avgdl = lengths.reduce((a, b) => a + b, 0) / N;
  const idf = {};
  for (const [term, n] of Object.entries(df)) {
    idf[term] = Math.log((N - n + 0.5) / (n + 0.5) + 1);
  }

  return { idf, avgdl, tfs, lengths, N };
}

function bm25Search(query, limit = 12) {
  const queryTokens = tokenize(query);
  if (queryTokens.length === 0) return [];

  const { idf, avgdl, tfs, lengths } = bm25Index;
  const scores = [];

  for (let i = 0; i < DATA.chunks.length; i++) {
    let score = 0;
    for (const qt of queryTokens) {
      const tf = tfs[i][qt] || 0;
      if (tf === 0) continue;
      const idfVal = idf[qt] || 0;
      const dl = lengths[i];
      score += idfVal * ((tf * (BM25_K1 + 1)) / (tf + BM25_K1 * (1 - BM25_B + BM25_B * dl / avgdl)));
    }
    if (score > 0) {
      scores.push({ chunkIdx: i, score });
    }
  }

  scores.sort((a, b) => b.score - a.score);
  return groupByDocument(scores, limit);
}

// ‚îÄ‚îÄ Semantic Search ‚îÄ‚îÄ
function cosineSimilarity(a, b) {
  let dot = 0, na = 0, nb = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    na += a[i] * a[i];
    nb += b[i] * b[i];
  }
  const denom = Math.sqrt(na) * Math.sqrt(nb);
  return denom === 0 ? 0 : dot / denom;
}

async function semanticSearch(query, limit = 12) {
  if (!modelReady) await loadModel();

  const result = await pipeline(query, { pooling: 'mean', normalize: true });
  const queryVec = Array.from(result.data);

  const scores = [];
  for (let i = 0; i < chunkEmbeddings.length; i++) {
    const sim = cosineSimilarity(queryVec, chunkEmbeddings[i]);
    if (sim > 0) scores.push({ chunkIdx: i, score: sim });
  }
  scores.sort((a, b) => b.score - a.score);
  return groupByDocument(scores, limit);
}

async function hybridSearch(query, limit = 12) {
  if (!modelReady) await loadModel();

  // Get keyword scores
  const queryTokens = tokenize(query);
  const kwScores = [];
  for (let i = 0; i < DATA.chunks.length; i++) {
    let score = 0;
    for (const qt of queryTokens) {
      const tf = bm25Index.tfs[i][qt] || 0;
      if (tf === 0) continue;
      const idfVal = bm25Index.idf[qt] || 0;
      const dl = bm25Index.lengths[i];
      score += idfVal * ((tf * (BM25_K1 + 1)) / (tf + BM25_K1 * (1 - BM25_B + BM25_B * dl / bm25Index.avgdl)));
    }
    kwScores.push(score);
  }

  // Get semantic scores
  const result = await pipeline(query, { pooling: 'mean', normalize: true });
  const queryVec = Array.from(result.data);
  const semScores = chunkEmbeddings.map(emb => cosineSimilarity(queryVec, emb));

  // Min-max normalize
  const normalize = (arr) => {
    const vals = arr.filter(v => v > 0);
    if (vals.length === 0) return arr.map(() => 0);
    const min = Math.min(...vals);
    const max = Math.max(...vals);
    if (max === min) return arr.map(v => v > 0 ? 1 : 0);
    return arr.map(v => v > 0 ? (v - min) / (max - min) : 0);
  };

  const kwNorm = normalize(kwScores);
  const semNorm = normalize(semScores);

  const combined = [];
  for (let i = 0; i < DATA.chunks.length; i++) {
    const score = (1 - HYBRID_ALPHA) * kwNorm[i] + HYBRID_ALPHA * semNorm[i];
    if (score > 0) combined.push({ chunkIdx: i, score });
  }

  combined.sort((a, b) => b.score - a.score);
  return groupByDocument(combined, limit);
}

// ‚îÄ‚îÄ Document Grouping (MAX aggregation) ‚îÄ‚îÄ
function groupByDocument(chunkScores, limit) {
  const docMap = {};
  for (const { chunkIdx, score } of chunkScores) {
    const chunk = DATA.chunks[chunkIdx];
    const docId = chunk.document_id;
    if (!docMap[docId] || score > docMap[docId].score) {
      docMap[docId] = { docId, score, bestChunkIdx: chunkIdx };
    }
  }

  const results = Object.values(docMap);
  results.sort((a, b) => b.score - a.score);

  return results.slice(0, limit).map(r => {
    const doc = DATA.documents.find(d => d.id === r.docId);
    const chunk = DATA.chunks[r.bestChunkIdx];
    return {
      id: doc.id,
      score: r.score,
      title: doc.title,
      source: doc.source,
      source_id: doc.source_id,
      updated_at: doc.updated_at,
      snippet: chunk.text.substring(0, 300),
      body: doc.body,
      chunks: DATA.chunks.filter(c => c.document_id === doc.id),
    };
  });
}

// ‚îÄ‚îÄ Transformers.js Model Loading ‚îÄ‚îÄ
let _modelPromise = null; // Shared promise so multiple callers wait on the same load

async function loadModel() {
  // If already ready, return immediately
  if (modelReady && pipeline && chunkEmbeddings) return;

  // If already loading, wait on the same promise (don't start a second load)
  if (_modelPromise) return _modelPromise;

  _modelPromise = _doLoadModel();
  return _modelPromise;
}

async function _doLoadModel() {
  const prog = document.getElementById('modelProgress');
  const hasCachedEmbeddings = chunkEmbeddings && chunkEmbeddings.length === DATA.chunks.length;

  // Only show progress if we need to embed chunks (not just load pipeline)
  if (!hasCachedEmbeddings) {
    prog.classList.add('visible');
  }

  try {
    if (!pipeline) {
      if (!hasCachedEmbeddings) {
        document.getElementById('progDetail').textContent = 'Loading Transformers.js library‚Ä¶';
        document.getElementById('progFill').style.width = '5%';
        document.getElementById('progPct').textContent = '5%';
      }

      const { pipeline: createPipeline, env } = await import(
        'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.5.1/dist/transformers.min.js'
      );

      env.allowLocalModels = false;

      if (!hasCachedEmbeddings) {
        document.getElementById('progDetail').textContent = 'Downloading all-MiniLM-L6-v2 model‚Ä¶';
        document.getElementById('progFill').style.width = '15%';
        document.getElementById('progPct').textContent = '15%';
      }

      pipeline = await createPipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2', {
        progress_callback: (p) => {
          if (!hasCachedEmbeddings && p.status === 'progress' && p.progress) {
            const pct = Math.round(15 + p.progress * 0.45);
            document.getElementById('progFill').style.width = pct + '%';
            document.getElementById('progPct').textContent = pct + '%';
            document.getElementById('progDetail').textContent = `Downloading model: ${p.file || ''}`;
          }
        }
      });
    }

    // Embed all chunks if not cached
    if (!hasCachedEmbeddings) {
      prog.classList.add('visible');
      document.getElementById('progDetail').textContent = `Embedding ${DATA.chunks.length} chunks‚Ä¶`;
      document.getElementById('progFill').style.width = '60%';
      document.getElementById('progPct').textContent = '60%';

      chunkEmbeddings = [];
      for (let i = 0; i < DATA.chunks.length; i++) {
        const result = await pipeline(DATA.chunks[i].text, { pooling: 'mean', normalize: true });
        chunkEmbeddings.push(Array.from(result.data));
        const pct = Math.round(60 + ((i + 1) / DATA.chunks.length) * 40);
        document.getElementById('progFill').style.width = pct + '%';
        document.getElementById('progPct').textContent = pct + '%';
        document.getElementById('progDetail').textContent = `Embedding chunk ${i + 1}/${DATA.chunks.length}‚Ä¶`;
      }

      // Cache embeddings in localStorage
      try {
        localStorage.setItem('ctx_chunk_embeddings', JSON.stringify(chunkEmbeddings));
        localStorage.setItem('ctx_chunk_hash', DATA.chunks.map(c => c.id).join(','));
      } catch (e) { /* storage full, no big deal */ }
    }

    modelReady = true;

    if (prog.classList.contains('visible')) {
      document.getElementById('progFill').style.width = '100%';
      document.getElementById('progPct').textContent = '100%';
      document.getElementById('progDetail').textContent = 'Ready! Model and embeddings cached for future visits.';
      setTimeout(() => prog.classList.remove('visible'), 2000);
    }

  } catch (e) {
    console.error('Model load error:', e);
    prog.classList.add('visible');
    document.getElementById('progDetail').textContent = `Error loading model: ${e.message}`;
    document.getElementById('progFill').style.background = 'var(--red)';
    document.getElementById('progFill').style.width = '100%';
    _modelPromise = null; // Allow retry
    throw e;
  }
}

// Try to load cached embeddings from localStorage
function loadCachedEmbeddings() {
  try {
    const hash = localStorage.getItem('ctx_chunk_hash');
    const expected = DATA.chunks.map(c => c.id).join(',');
    if (hash === expected) {
      const cached = JSON.parse(localStorage.getItem('ctx_chunk_embeddings'));
      if (cached && cached.length === DATA.chunks.length) {
        chunkEmbeddings = cached;
        return true;
      }
    }
  } catch (e) { /* cache miss */ }
  return false;
}

// ‚îÄ‚îÄ UI Functions ‚îÄ‚îÄ
window.setMode = function(btn) {
  const mode = btn.dataset.mode;
  document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
  currentMode = mode;
  document.getElementById('modeExplainer').innerHTML = MODE_EXPLANATIONS[mode];
};

window.trySuggestion = function(btn) {
  document.getElementById('searchInput').value = btn.textContent;
  doSearch();
};

window.doSearch = async function() {
  const query = document.getElementById('searchInput').value.trim();
  if (!query || !DATA) return;

  const area = document.getElementById('resultsArea');
  const suggestions = document.getElementById('suggestionsArea');
  suggestions.style.display = 'none';
  area.innerHTML = '<div class="loading"><div class="spinner"></div>Searching‚Ä¶</div>';
  document.getElementById('statsBar').classList.remove('visible');

  const t0 = performance.now();

  try {
    let results;
    if (currentMode === 'keyword') {
      results = bm25Search(query);
    } else if (currentMode === 'semantic') {
      results = await semanticSearch(query);
    } else {
      results = await hybridSearch(query);
    }

    // Normalize scores to 0-1 range for display
    if (results.length > 0) {
      const maxScore = results[0].score;
      if (maxScore > 0) {
        results.forEach(r => r.score = r.score / maxScore);
      }
    }

    const elapsed = Math.round(performance.now() - t0);

    document.getElementById('statsBar').classList.add('visible');
    document.getElementById('statCount').textContent = results.length;
    document.getElementById('statMode').textContent = currentMode;
    document.getElementById('statTime').textContent = `${elapsed}ms`;

    if (results.length === 0) {
      area.innerHTML = `<div class="empty-state"><div class="icon">üì≠</div><h3>No results</h3><p>${currentMode === 'keyword' ? 'No exact term matches. Try <strong>semantic</strong> mode to find conceptually related content.' : 'Try different terms or switch modes.'}</p></div>`;
      return;
    }

    const modeExplain = {
      keyword: 'BM25 (term frequency / document length)',
      semantic: 'cosine similarity between query and chunk embeddings',
      hybrid: 'a weighted merge of BM25 (40%) and cosine similarity (60%)',
    };

    area.innerHTML = `
      <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:12px;font-size:13px;color:var(--text-dim)">
        <span>${results.length} result${results.length !== 1 ? 's' : ''}</span>
        <span style="font-family:var(--mono)">${elapsed}ms ¬∑ browser</span>
      </div>
      ${results.map((r, i) => renderResult(r, i)).join('')}
      <div class="result-learn">
        <strong>üí° How these results were ranked:</strong> Each of the ${DATA.chunks.length} chunks was scored using ${modeExplain[currentMode]}. Chunks were grouped by parent document (MAX score wins). The top chunk's score became the document's score. ${currentMode === 'keyword' ? 'Try the same query in <strong>semantic</strong> mode ‚Äî you may discover results that keyword search missed.' : currentMode === 'semantic' ? 'Notice how results appear even without exact word matches ‚Äî the model understands meaning.' : 'Hybrid mode catches both exact matches and conceptual similarity.'}
      </div>`;

  } catch (e) {
    console.error('Search error:', e);
    const msg = e.message || String(e);
    const isModelError = msg.includes('model') || msg.includes('pipeline') || msg.includes('transformers') || msg.includes('fetch');
    area.innerHTML = `<div class="error-msg">${isModelError
      ? 'Failed to load the AI model for semantic search. This may be due to browser restrictions, ad blockers, or network issues.<br><br>Try <strong>keyword</strong> mode instead, or refresh the page and try again.'
      : `Search error: ${escapeHtml(msg)}`}</div>`;
  }
};

function renderResult(r, idx) {
  const score = r.score.toFixed(2);
  const scoreClass = r.score >= 0.7 ? 'score-high' : r.score >= 0.4 ? 'score-mid' : 'score-low';
  const date = r.updated_at ? r.updated_at.split('T')[0] : '';

  const scoreExplain = r.score >= 0.7
    ? 'Strong match ‚Äî this chunk had high relevance to your query'
    : r.score >= 0.4
    ? 'Moderate match ‚Äî some relevant content found'
    : 'Weak match ‚Äî only partially related';

  return `
    <div class="result-card" onclick="toggleDetail(${idx})">
      <div class="result-header">
        <span class="result-title">${escapeHtml(r.title)}</span>
        <span class="result-score ${scoreClass}" title="${scoreExplain}">${score}</span>
      </div>
      <div class="result-meta">
        <span>üìÅ ${escapeHtml(r.source)}</span>
        <span>üìÑ ${escapeHtml(r.source_id)}</span>
        ${date ? `<span>üìÖ ${date}</span>` : ''}
        <span class="browser-badge badge-browser">computed locally</span>
      </div>
      <div class="result-snippet">${escapeHtml(r.snippet)}${r.snippet.length >= 300 ? '‚Ä¶' : ''}</div>
      <div class="result-learn">
        <strong>Score ${score}:</strong> ${scoreExplain}. ${currentMode === 'keyword' ? 'BM25 scored this chunk based on how many of your query terms appeared and how concentrated they were relative to the chunk length.' : currentMode === 'semantic' ? 'Cosine similarity measured how closely the meaning of this chunk aligned with your query, even without exact word matches.' : 'This score is a weighted blend of keyword relevance (40%) and semantic similarity (60%).'}
      </div>
      <div class="doc-detail" id="detail-${idx}" data-doc='${JSON.stringify({ body: r.body, chunks: r.chunks }).replace(/'/g, '&#39;')}'>
      </div>
    </div>`;
}

window.toggleDetail = function(idx) {
  const el = document.getElementById(`detail-${idx}`);
  if (el.classList.contains('visible')) {
    el.classList.remove('visible');
    el.innerHTML = '';
    return;
  }

  const data = JSON.parse(el.dataset.doc);

  el.innerHTML = `
    <div class="doc-learn">
      <strong>üí° What you're seeing:</strong> This is the full document. It was split into <strong>${data.chunks.length} chunk${data.chunks.length !== 1 ? 's' : ''}</strong> during ingestion. Each chunk is a ~500-token segment split at paragraph boundaries. Search scored each chunk individually, then grouped them back to this parent document using MAX aggregation.
    </div>
    <div style="margin-top:10px">
      ${data.chunks.map(c => `<span class="chunk-tag">chunk ${c.chunk_index} ¬∑ ${c.text.length} chars</span>`).join('')}
    </div>
    <div class="doc-body">${escapeHtml(data.body)}</div>
  `;
  el.classList.add('visible');
};

function escapeHtml(text) {
  const div = document.createElement('div');
  div.textContent = text;
  return div.innerHTML;
}

// ‚îÄ‚îÄ Init ‚îÄ‚îÄ
async function init() {
  try {
    const resp = await fetch('data.json');
    DATA = await resp.json();

    // Build BM25 index
    bm25Index = buildBM25Index(DATA.chunks);

    // Try loading cached embeddings, then warm up the pipeline in the background
    const hasCached = loadCachedEmbeddings();

    document.getElementById('statusText').textContent =
      `${DATA.documents.length} docs ¬∑ ${DATA.chunks.length} chunks ¬∑ browser`;

    if (hasCached) {
      // Embeddings are cached ‚Äî load model pipeline in background (no progress bar)
      loadModel().catch((e) => {
        console.warn('Background model load failed (semantic will retry on first query):', e.message);
        _modelPromise = null; // Allow retry on first search
      });
    }

  } catch (e) {
    document.getElementById('statusText').textContent = 'error loading data';
    console.error('Failed to load data:', e);
  }
}

document.getElementById('searchInput').addEventListener('keydown', (e) => {
  if (e.key === 'Enter') doSearch();
});

init();

</script>
</body>
</html>

